ML Kernel Optimization on CPU

Goal: Implement a small ML kernel (e.g., convolution or matrix multiply) in C++, optimize it for CPU performance using multi-threading, vectorization, or ARM NEON/SVE (you can use a Raspberry Pi or ARM VM for testing).

Impact: Shows hands-on experience in low-level optimization for CPU/NPU, which aligns with their SME/SVE focus.

Optional addition: Measure latency, throughput, memory usage, and compare baseline vs optimized version.